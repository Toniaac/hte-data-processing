{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 预设函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_tempimg(image):\n",
    "    '''\n",
    "    先清空当前文件夹，然后保存图片到temp_img文件夹下\n",
    "    input: \n",
    "        a cv2 format image\n",
    "    output:\n",
    "        None (save image to temp_img/)\n",
    "    '''\n",
    "    all_files = os.listdir(\"temp_img/\") # 获取目录下所有文件和目录\n",
    "\n",
    "    # 遍历所有文件和子目录\n",
    "    for file_or_dir in all_files:\n",
    "        # 构建完整的文件或目录路径\n",
    "        file_or_dir_path = os.path.join(\"temp_img/\", file_or_dir)\n",
    "        \n",
    "        # 检查是否是文件并删除\n",
    "        if os.path.isfile(file_or_dir_path):\n",
    "            os.remove(file_or_dir_path) # 删除temp_img文件夹下的所有文件\n",
    "\n",
    "    cv2.imwrite('temp_img/temp.png', image) # 保存 temp.png\n",
    "\n",
    "def save_tempimg2(image):\n",
    "    '''\n",
    "    先清空当前文件夹，然后保存temp2图片到temp_img文件夹下\n",
    "    input: \n",
    "        a cv2 format image\n",
    "    output:\n",
    "        None (save image to temp_img/)\n",
    "    '''\n",
    "    cv2.imwrite('temp_img/temp2.png', image)\n",
    "\n",
    "def save_tempimg3(image):\n",
    "    '''\n",
    "    先清空当前文件夹，然后保存temp3图片到temp_img文件夹下\n",
    "    input: \n",
    "        a cv2 format image\n",
    "    output:\n",
    "        None (save image to temp_img/)\n",
    "    '''\n",
    "    cv2.imwrite('temp_img/temp3.png', image)\n",
    "\n",
    "# def generate_padding(image, border_size=1):\n",
    "#     '''\n",
    "#     老版for loop brightness difference processing所使用的函数\n",
    "#     为图像添加padding\n",
    "#     input: \n",
    "#         image: a cv2 format image\n",
    "#         border_size: int, padding size\n",
    "#     output:\n",
    "#         padded_image: a cv2 format image\n",
    "#     '''\n",
    "#     # Get the dimensions of the original image\n",
    "#     height, width = image.shape\n",
    "\n",
    "#     # Create a new image with the desired size\n",
    "#     padded_image = np.zeros((height + 2 * border_size, width + 2 * border_size), dtype=np.uint8)\n",
    "\n",
    "#     # Copy the original image to the center of the new image\n",
    "#     padded_image[border_size:border_size+height, border_size:border_size+width] = image\n",
    "\n",
    "#     return padded_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 读取图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "image = cv2.imread('4.jpg', cv2.IMREAD_GRAYSCALE) #在这里更改图片路径"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brightness Difference Processing (第一部分)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 老版for loop代码\n",
    "# brightness_color_diff = image.copy()\n",
    "# image_with_padding = generate_padding(image)\n",
    "\n",
    "# threshold_difference = 4\n",
    "# for i in tqdm(range(len(brightness_color_diff))): # for each row\n",
    "#     for j in range(len(brightness_color_diff[i])): # for each column\n",
    "#         current = int(image_with_padding[i][j])\n",
    "#         top = int(image_with_padding[i-1][j])\n",
    "#         bot = int(image_with_padding[i+1][j])\n",
    "#         left = int(image_with_padding[i][j-1])\n",
    "#         right = int(image_with_padding[i][j+1])\n",
    "#         top_diff = abs(current - top)\n",
    "#         bot_diff = abs(current - bot)\n",
    "#         left_diff = abs(current - left)\n",
    "#         right_diff = abs(current - right)\n",
    "#         diff = max(top_diff, bot_diff, left_diff, right_diff)\n",
    "#         if diff > threshold_difference or brightness_color_diff[i][j] <= 150:\n",
    "#             brightness_color_diff[i][j] = 0 \n",
    "#         if brightness_color_diff[i][j] > 150:\n",
    "#             brightness_color_diff[i][j] = 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_padding(image, pad_width=1, pad_value=0):\n",
    "    \"\"\"为图像生成周围的填充（padding）。\"\"\"\n",
    "    return np.pad(image, ((pad_width, pad_width), (pad_width, pad_width)), 'constant', constant_values=(pad_value,))\n",
    "\n",
    "# 假设 `image` 是一个灰度图像\n",
    "image = cv2.imread('3.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "image_with_padding = generate_padding(image)\n",
    "\n",
    "image = image.astype(np.int16)\n",
    "image_with_padding = image_with_padding.astype(np.int16)\n",
    "\n",
    "# 使用向量化方式进行处理\n",
    "threshold_difference = 4\n",
    "# 计算相邻像素之间的差异\n",
    "top_diff = np.abs(image_with_padding[:-2, 1:-1] - image_with_padding[1:-1, 1:-1]) # [:-2, 1:-1]表示去除了最后两行和第一列+最后一列的所有行和列, [1:-1, 1:-1]表示去除了第一行+最后一行和第一列+最后一列的所有行和列\n",
    "bot_diff = np.abs(image_with_padding[2:, 1:-1] - image_with_padding[1:-1, 1:-1]) # [2:, 1:-1]表示去除了前两行和第一列+最后一列的所有行和列, [1:-1, 1:-1]表示去除了第一行+最后一行和第一列+最后一列的所有行和列\n",
    "left_diff = np.abs(image_with_padding[1:-1, :-2] - image_with_padding[1:-1, 1:-1]) # [1:-1, :-2]表示去除了第一行+最后一行和最后两列的所有行和列, [1:-1, 1:-1]表示去除了第一行+最后一行和第一列+最后一列的所有行和列\n",
    "right_diff = np.abs(image_with_padding[1:-1, 2:] - image_with_padding[1:-1, 1:-1])  # [1:-1, 2:]表示去除了第一行+最后一行和前两列的所有行和列, [1:-1, 1:-1]表示去除了第一行+最后一行和第一列+最后一列的所有行和列\n",
    "\n",
    "# 计算最大差异\n",
    "# max_diff = np.maximum(np.maximum(top_diff, bot_diff), np.maximum(left_diff, right_diff))\n",
    "max_diff = np.maximum(np.maximum(np.maximum(top_diff, bot_diff), left_diff), right_diff)\n",
    "\n",
    "# 应用阈值条件\n",
    "brightness_color_diff = image.copy()\n",
    "brightness_color_diff[image > 150] = 255\n",
    "brightness_color_diff[image <= 150] = 0\n",
    "brightness_color_diff[max_diff > threshold_difference] = 0\n",
    "\n",
    "image = image.astype(np.int8)\n",
    "image_with_padding = image_with_padding.astype(np.int8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 所有处理过的图片都会保存在temp_img/ 文件夹中，如果没有此文件夹，请先在根目录下建立一个名为\"temp_img\"的文件夹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_tempimg(brightness_color_diff) # 保存图片到temp_img文件夹下"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Denoising (第二部分)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 本部分一共尝试过三种算法\n",
    "1. intergral image\n",
    "2. intergral image vectorized\n",
    "3. 2D Convolution\n",
    "- PPT中展示的结果是第一种算法（integral image）得到的结果 耗时约为10s\n",
    "- 第二种算法没有完全debug，虽然计算速度非常快（<1s），但是得到的结果和第一种算法不一致\n",
    "- Convolution算法并没有完全适配，可能会出现长达几十分钟的运行时间，不推荐使用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integral Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def calculate_integral_image(image):\n",
    "    integral_image = np.cumsum(np.cumsum(image, axis=0), axis=1)\n",
    "    return integral_image\n",
    "\n",
    "def fast_thresholding(image, kernel_n, threshold):\n",
    "    # Calculate the integral image\n",
    "    integral_image = calculate_integral_image(image)\n",
    "\n",
    "    # Create an output image\n",
    "    output_image = np.ones_like(image) * 255\n",
    "    threshold_value = (kernel_n**2) * threshold\n",
    "\n",
    "    # Calculate border size\n",
    "    border_size = kernel_n // 2\n",
    "\n",
    "    # Iterate over each pixel in the original image\n",
    "    for y in range(border_size, image.shape[0] - border_size):\n",
    "        for x in range(border_size, image.shape[1] - border_size):\n",
    "            # Calculate the sum of the kernel area using the integral image\n",
    "            total = integral_image[y + border_size, x + border_size]\n",
    "            total -= integral_image[y + border_size, x - border_size - 1]\n",
    "            total -= integral_image[y - border_size - 1, x + border_size]\n",
    "            total += integral_image[y - border_size - 1, x - border_size - 1]\n",
    "            # Calculate the number of black pixels (assuming black is 0 and white is 255)\n",
    "            black_pixel_count = (kernel_n**2) - total / 255\n",
    "            # Apply threshold\n",
    "            if black_pixel_count > threshold_value:\n",
    "                output_image[y, x] = 0\n",
    "\n",
    "    return output_image\n",
    "\n",
    "# Applying the optimized thresholding function\n",
    "output = fast_thresholding(brightness_color_diff, kernel_n=9, threshold=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_tempimg2(output) # 保存图片到temp_img文件夹下"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integral Image Vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# def fast_thresholding_vectorized(image, kernel_n=9, threshold=0.2):\n",
    "#     # Calculate the integral image\n",
    "#     integral_image = np.cumsum(np.cumsum(image, axis=0), axis=1)\n",
    "    \n",
    "#     # Expand the integral image by padding to handle borders\n",
    "#     padded_integral = np.pad(integral_image, ((kernel_n//2+1,), (kernel_n//2+1,)), 'constant', constant_values=0)\n",
    "    \n",
    "#     # Calculate sums over the kernel for each pixel in a vectorized manner\n",
    "#     total = (\n",
    "#         padded_integral[kernel_n:, kernel_n:] - \n",
    "#         padded_integral[:-kernel_n, kernel_n:] - \n",
    "#         padded_integral[kernel_n:, :-kernel_n] + \n",
    "#         padded_integral[:-kernel_n, :-kernel_n]\n",
    "#     )\n",
    "    \n",
    "#     # Calculate the average intensity within the kernel area for each pixel\n",
    "#     avg_intensity = total / (kernel_n ** 2)\n",
    "    \n",
    "#     # Create an output image based on the threshold\n",
    "#     # Assume black is 0 and white is 255\n",
    "#     output_image = np.where(avg_intensity <= threshold * 255, 0, 255).astype(np.uint8)\n",
    "    \n",
    "#     # Adjust the output image size to match the input image size\n",
    "#     output_image = output_image[(kernel_n//2):-((kernel_n-1)//2), (kernel_n//2):-((kernel_n-1)//2)]\n",
    "    \n",
    "#     return output_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# denoised_img = fast_thresholding_vectorized(brightness_color_diff, kernel_n=9, threshold=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_tempimg3(denoised_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.signal import convolve2d\n",
    "# kernel_n = 9 # must be odd\n",
    "# threshold = 0.4                             # Adjustable threshold value\n",
    "# kernel = np.ones((kernel_n, kernel_n))\n",
    "# result_array = convolve2d(brightness_color_diff, kernel, mode='same', boundary='fill', fillvalue=0)\n",
    "# # multiply result_array by 1/225\n",
    "# white_pixel_count = result_array / 255\n",
    "# black_pixel_ratio = (81 - white_pixel_count) / 81"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_convolution_test = brightness_color_diff.copy()\n",
    "# for i in tqdm(range(len(img_convolution_test))):\n",
    "#     for j in range(len(img_convolution_test[i])):\n",
    "#         if black_pixel_ratio[i][j] < threshold:\n",
    "#             img_convolution_test[i][j] = 255\n",
    "#         else:\n",
    "#             img_convolution_test[i][j] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_tempimg2(img_convolution_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uniform Region Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniform_region_detection(image, kernel_n):\n",
    "    # Calculate the integral image\n",
    "    integral_image = calculate_integral_image(image)\n",
    "\n",
    "    # Create an output image\n",
    "    output_image = image.copy()\n",
    "\n",
    "    # Calculate border size\n",
    "    border_size = kernel_n // 2\n",
    "\n",
    "    # Iterate over each pixel in the original image\n",
    "    for y in range(border_size, image.shape[0] - border_size):\n",
    "        for x in range(border_size, image.shape[1] - border_size):\n",
    "            # Calculate the sum of the kernel area using the integral image\n",
    "            total = integral_image[y + border_size, x + border_size]\n",
    "            total -= integral_image[y + border_size, x - border_size - 1]\n",
    "            total -= integral_image[y - border_size - 1, x + border_size]\n",
    "            total += integral_image[y - border_size - 1, x - border_size - 1]\n",
    "            # Calculate the number of black pixels (assuming black is 0 and white is 255)\n",
    "            black_pixel_count = (kernel_n**2) - total / 255\n",
    "            # Apply threshold\n",
    "            if black_pixel_count == 0:\n",
    "                output_image[y, x] = 170 # gray color for region able for processing\n",
    "\n",
    "    return output_image\n",
    "\n",
    "image_uniform = uniform_region_detection(output, kernel_n=301)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_tempimg3(image_uniform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test point calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 本部分是花费最多时间的地方，需要更多的优化\n",
    "- 给出是否能进行试验的结论，如果可以给出用于测试的位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Check if 170 in the image\n",
    "def check_170(image):\n",
    "    for i in range(len(image)):\n",
    "        for j in range(len(image[i])):\n",
    "            if image[i][j] == 170:\n",
    "                return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if check_170(image_uniform) == True:\n",
    "    max_distance = 0\n",
    "    max_cordinate = (0, 0)\n",
    "    for i in range(len(image_uniform)):\n",
    "        for j in range(len(image_uniform[i])):\n",
    "            if image_uniform[i][j] == 170:\n",
    "                distance = 0\n",
    "                try: # Avoid index out of range\n",
    "                    if image_uniform[i+max_distance][j] and image_uniform[i-max_distance][j] and image_uniform[i][j+max_distance] and image_uniform[i][j-max_distance] == 170:\n",
    "                        max_cordinate = (i, j)\n",
    "                        while image_uniform[i+distance][j] and image_uniform[i-distance][j] and image_uniform[i][j+distance] and image_uniform[i][j-distance] == 170:\n",
    "                            distance += 1\n",
    "                            max_distance = distance\n",
    "                    else:\n",
    "                        continue\n",
    "                except:\n",
    "                    continue\n",
    "    print(\"The pixel to conduct the processing is: \", max_cordinate, \"with the distance of: \", max_distance)\n",
    "else:\n",
    "    print(\"No pixel to conduct the processing\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
